{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setting up the base directory and initial configurations\n",
    "    ### To Do\n",
    "        * preliminary analysis\n",
    "        * preprocessing\n",
    "            * identify categorical variables\n",
    "            * missing value imputation\n",
    "        * Feature Selection\n",
    "            * run rf with selected features\n",
    "            * use GA to select features\n",
    "            * encode GA urself\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "folder_name = \"/springleaf_marketing_response/\"\n",
    "base_dir = \"/Users/gulshan/kaggle/\"\n",
    "data_dir = base_dir+\"/data/\"+folder_name\n",
    "output_dir = base_dir+\"/output/\"+folder_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(145231, 1934) (145232, 1933)\n"
     ]
    }
   ],
   "source": [
    "train_data_orig=pd.read_csv(data_dir+\"/train.csv\")\n",
    "test_data_orig=pd.read_csv(data_dir+\"/test.csv\")\n",
    "print train_data_orig.shape,test_data_orig.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary Analysis Pipeline\n",
    "    * dtype of columns\n",
    "    * missing value check\n",
    "    * distribution plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_copy=train_data_orig.copy()\n",
    "test_copy=test_data_orig.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colnames=train_copy.columns.values\n",
    "def get_type(input):\n",
    "    for values in input:\n",
    "        if type(values)==str:\n",
    "            return(str)\n",
    "            break\n",
    "    \n",
    "str_colnames=[x for x in colnames if get_type(train_copy[x])==str]\n",
    "n_cat=[len(set(train_copy[x])) for x in str_colnames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_missing_value_column_dict(input_df):\n",
    "    \"\"\"\n",
    "    return counter dict where keys are column names and values are number of missing values\n",
    "    {\n",
    "    'VAR_0669': 0,\n",
    "    'VAR_0460': 918,\n",
    "    }\n",
    "    \"\"\"\n",
    "    missing_value_counter={}\n",
    "    colnames=input_df.columns.values\n",
    "    for names in colnames:\n",
    "        tmp_df=pd.isnull(input_df[names])\n",
    "        count=len(tmp_df[tmp_df==True])\n",
    "        missing_value_counter[names]=count\n",
    "    return missing_value_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "missing_value_dict=get_missing_value_column_dict(train_copy)\n",
    "missing_value_columns=[x for x in missing_value_dict.keys() if missing_value_dict[x]>0]\n",
    "missing_value_str_columns=list(set(missing_value_columns).intersection(set(str_colnames)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def missing_value_imputation(df,colnames,filler):\n",
    "    \"\"\"\n",
    "    in place imputation for missing values\n",
    "    \"\"\"\n",
    "    for key in colnames:\n",
    "        df[key]=df[key].fillna(value=filler)\n",
    "#         print df[key]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "missing_value_imputation(train_copy,list(set(missing_value_columns)-set(missing_value_str_columns)),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# missing_value_imputation(train_copy,missing_value_str_columns,\"NA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for key in missing_value_str_columns:\n",
    "    print key,len(set(train_copy[key]))\n",
    "#     if len(set(train_copy[key]))<10:\n",
    "#         print set(train_copy[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert VAR_0217 to month\n",
    "#VAR_0200 is location names \n",
    "#VAR_0404 is designation VAR_0493\n",
    "#VAR_0204 time stamp VAR_0075:more varied\n",
    "\n",
    "# set(train_copy['VAR_0342'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data=train_copy[list(set(colnames)-set(str_colnames))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# col=train_data.columns.values\n",
    "# for key in col:\n",
    "#     if \"26APR12:00:00:00\" in list(train_data[key]):\n",
    "#         print key \n",
    "#VAR_0073 VAR_0156 VAR_0157 VAR_0158 VAR_0159"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target=train_data['target']\n",
    "train=train_data.drop(['ID','target'], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colnames_test=test_copy.columns.values\n",
    "str_colnames_test=[x for x in colnames_test if get_type(test_copy[x])==str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "missing_value_dict=get_missing_value_column_dict(test_copy)\n",
    "missing_value_columns=[x for x in missing_value_dict.keys() if missing_value_dict[x]>0]\n",
    "missing_value_str_columns=list(set(missing_value_columns).intersection(set(str_colnames_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "missing_value_imputation(test_copy,list(set(missing_value_columns)-set(missing_value_str_columns)),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data=test_copy[list(set(colnames_test)-set(str_colnames_test))]\n",
    "test=test_data.drop('ID',1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Preprocessing Pipeline\n",
    "    * Imputation of missing values\n",
    "    * Encoding categorical features\n",
    "    * Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class preprocess:\n",
    "    def one_hot_encoding(input_array):\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of 100 | elapsed:    7.9s remaining: 13.0min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  3.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11min 13s, sys: 32.3 s, total: 11min 45s\n",
      "Wall time: 4min 11s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
       "            oob_score=False, random_state=None, verbose=1,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Create the random forest object which will include all the parameters\n",
    "# for the fit\n",
    "rf = RandomForestClassifier(n_estimators = 100,n_jobs=-1, verbose =1)\n",
    "%time rf.fit(train, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 out of 100 | elapsed:    0.3s remaining:   26.2s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    6.0s finished\n"
     ]
    }
   ],
   "source": [
    "submission=pd.DataFrame()\n",
    "ID=test_data['ID']\n",
    "output = rf.predict(test)\n",
    "# output=[0]*len(ID)\n",
    "submission['ID']=ID\n",
    "submission['target']=output\n",
    "submission.to_csv(data_dir+'submission_2.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  target\n",
       "0   1       0\n",
       "1   3       0\n",
       "2   6       0\n",
       "3   9       0\n",
       "4  10       1"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
